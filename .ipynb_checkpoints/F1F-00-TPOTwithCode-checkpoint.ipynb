{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLIP(01):  Advanced Data Science\n",
    "**(Tools Module 04: TPOP)**\n",
    "\n",
    "---\n",
    "- Materials in this module include resources collected from various open-source online repositories.\n",
    "- You are free to use, but NOT allowed to change or distribute this package.\n",
    "\n",
    "Prepared by and for \n",
    "**Student Members** |\n",
    "2006-2018 [TULIP Lab](http://www.tulip.org.au)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Session 00 - TPOT with code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've taken care to design the TPOT interface to be as similar as possible to scikit-learn.\n",
    "\n",
    "TPOT can be imported just like any regular Python module. To import TPOT, type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then create an instance of TPOT as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_optimizer = TPOTClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to use TPOT for regression problems with the `TPOTRegressor` class. Other than the class name, a `TPOTRegressor` is used the same way as a `TPOTClassifier`. You can read more about the `TPOTClassifier` and `TPOTRegressor` classes in the API documentation().\n",
    "\n",
    "Some example code with custom TPOT parameters might look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_optimizer = TPOTClassifier(generations=5, population_size=20, cv=5,\n",
    "                                    random_state=42, verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now TPOT is ready to optimize a pipeline for you. You can tell TPOT to optimize a pipeline based on a data set with the `fit` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_optimizer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit` function initializes the genetic programming algorithm to find the highest-scoring pipeline based on average k-fold cross-validation Then, the pipeline is trained on the entire set of provided samples, and the TPOT instance can be used as a fitted model.\n",
    "\n",
    "You can then proceed to evaluate the final pipeline on the testing set with the `score` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline_optimizer.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can tell TPOT to export the corresponding Python code for the optimized pipeline to a text file with the `export` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_optimizer.export('tpot_exported_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this code finishes running, `tpot_exported_pipeline.py` will contain the Python code for the optimized pipeline.\n",
    "\n",
    "Below is a full example script using TPOT to optimize a pipeline, score it, and export the best pipeline to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target,\n",
    "                                                    train_size=0.75, test_size=0.25)\n",
    "\n",
    "pipeline_optimizer = TPOTClassifier(generations=5, population_size=20, cv=5,\n",
    "                                    random_state=42, verbosity=2)\n",
    "pipeline_optimizer.fit(X_train, y_train)\n",
    "print(pipeline_optimizer.score(X_test, y_test))\n",
    "pipeline_optimizer.export('tpot_exported_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "tpot = TPOTRegressor(generations=20, population_size=20,\n",
    "                         offspring_size=None, mutation_rate=0.9,\n",
    "                         crossover_rate=0.1,\n",
    "                         scoring='neg_mean_absolute_error', cv=5,\n",
    "                         subsample=1, n_jobs=1,\n",
    "                         max_time_mins=None, max_eval_time_mins=5,\n",
    "                         random_state=42, config_dict=None,\n",
    "                         warm_start=False,\n",
    "                         memory=None,\n",
    "                         use_dask=False,\n",
    "                         periodic_checkpoint_folder=None,\n",
    "                         early_stop=500,\n",
    "                         verbosity=2,\n",
    "                         disable_update_check=True)\n",
    "model=tpot.fit(x_train, y_train)\n",
    "print(tpot.score(x_test, y_test))\n",
    "tpot.export('tpot_欧莱雅_pipeline_cv_10.py')\n",
    "f = open(\"tpot_欧莱雅_pipeline_cv_10.py\")\n",
    "code = f.read()\n",
    "import re\n",
    "pat = '(.*?)\\n\\n# NOTE'\n",
    "code0= re.compile(pat, re.S).findall(code)\n",
    "exec(code0[0])\n",
    "\n",
    "pat = 'exported_pipeline = (.*?)\\n\\nexported_pipeline'\n",
    "code1= re.compile(pat, re.S).findall(code)\n",
    "exported_pipeline=eval(code1[0])\n",
    "model=exported_pipeline.fit(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
